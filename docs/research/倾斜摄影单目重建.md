# **面向倾斜摄影、无人机与单目视频的三维重建开源算法研究**

## **I. 多样化视觉输入的三维重建技术导论**

### **A. 三维重建在现代应用中的迫切需求**

近年来，三维模型在城市规划、文化遗产保护、机器人技术、自主系统、娱乐产业以及工业检测等众多领域的应用需求日益增长。这种增长趋势凸显了对稳健且易于获取的三维重建方法的迫切需求。例如，在建筑、三维制图、机器人、增强现实以及历史古迹保护等领域，三维重建技术已展现出其广泛的应用前景和巨大的影响力 1。

### **B. 主要视觉数据模态概述**

三维重建技术依赖于多种视觉数据输入源，主要包括倾斜摄影、无人机影像和单目视频。

* **倾斜摄影 (Oblique Photography)**：该技术通过倾斜相机轴线获取影像，能够捕捉到传统垂直（Nadir）摄影中容易忽略的物体垂直表面信息 2。这对于精细化的建筑立面建模和创建逼真的三维城市模型具有重要价值。  
* **无人机影像 (UAV Imagery)**：无人机（UAV）作为一种灵活的空中平台，能够获取用于三维测绘与建模的航空影像，包括垂直和倾斜影像 1。其优势在于成本效益高、部署迅速以及能够进入难以到达的区域。  
* **单目视频 (Monocular Video)**：单目视频是指由单个摄像机（通常为手持或车载）获取的视频序列，是一种普遍存在的数据源 7。尽管其本身存在一些挑战，例如缺乏直接深度信息和尺度模糊性，但在动态场景捕捉和实时应用方面具有巨大潜力。

### **C. 开源算法的关键作用**

开源软件和算法在推动三维重建技术的发展中扮演着至关重要的角色。它们不仅加速了科学研究的进程，促进了技术创新，还使得先进的三维重建技术能够被更广泛的用户群体所接触和使用 9。开源社区的协作特性及其在建立通用基础设施和基准测试方面的重要性不容忽视。

### **D. 报告范围与目标**

本报告旨在深入研究和分析用于倾斜摄影、无人机影像和单目视频三维重建的开源算法和软件。报告将重点探讨这些技术的基本原理、工作流程、核心功能及其局限性，并结合现有研究成果进行阐述。

尽管倾斜摄影、无人机影像和单目视频是三种不同的数据模态，但在实际的三维重建应用中，它们日益显示出互补使用的趋势。例如，无人机可以同时获取垂直和倾斜影像 3，而为单目视频开发的技术（如SLAM）也与处理连续的无人机影像序列相关。最终目标往往是构建一个完整且详细的三维场景，这可能需要融合来自不同来源的数据 12。这种趋势表明，未来的三维重建将更加侧重于整体化的场景理解和数据融合能力。

此外，开源领域呈现出一种双重发展趋势：一方面是针对特定任务高度专业化的工具（例如，用于单目惯性数据的SLAM系统VINS-Mono 13）；另一方面是提供基础构建模块的通用库（例如，OpenCV 9 和Open3D 10）。众多专业化开源项目的存在表明复杂问题通常需要定制化的解决方案。然而，像OpenCV（提供图像处理、基础SfM组件）和Open3D（提供三维数据结构、类似PCL的功能）这样的通用库所提供的基础，对于这些专业化工具的有效构建至关重要。这种专业化与通用化的相互作用共同推动了技术的创新。更广泛地看，通过开源工具实现三维建模的普及，不仅仅是降低成本，更重要的是为那些以前无法承担或接触专有解决方案的领域开辟了新的研究途径和应用前景，从而加速了创新和技术应用的循环。

## **II. 基于图像的三维重建基础技术**

基于图像的三维重建依赖于一系列核心技术，这些技术从二维图像中提取信息以推断三维结构。主要技术包括运动恢复结构 (Structure from Motion, SfM)、多视图立体匹配 (Multi-View Stereo, MVS) 和同时定位与地图构建 (Simultaneous Localization and Mapping, SLAM)。近年来，深度学习也为这些领域带来了范式转变。

### **A. 运动恢复结构 (SfM)：从运动中推断几何**

SfM的核心原理是通过分析一系列二维图像来重建场景的三维结构以及估计相机在拍摄这些图像时的姿态（位置和方向）1。该过程首先从输入图像中提取显著的视觉特征，如角点、边缘或其他可区分的点。常用的特征描述子包括SIFT (Scale-Invariant Feature Transform) 和SURF (Speeded Up Robust Features)。

SfM的关键工作流程步骤包括：

1. **特征提取 (Feature Extraction)**：在输入图像中识别出独特的特征点 3。  
2. **特征匹配 (Feature Matching)**：在不同图像之间建立这些特征点的对应关系 3。  
3. **相机姿态估计 (Camera Pose Estimation)**：基于匹配的特征点，估计每张图像拍摄时相机的相对位置和朝向 3。  
4. **三角化 (Triangulation)**：利用已估计的相机姿态和匹配的二维特征点，通过几何约束计算出这些特征点在三维空间中的位置 3。  
5. **光束法平差 (Bundle Adjustment)**：这是一个联合优化过程，同时调整相机参数（内外参数）和三维点坐标，以最小化三维点在图像上的重投影误差。光束法平差对于提高重建的精度至关重要 1。

SfM技术面临的挑战包括对图像质量的敏感性、在缺乏纹理或存在重复纹理的区域表现不佳，以及处理大规模数据集时的高计算成本 15。SfM是倾斜摄影和无人机影像三维重建的基石。

### **B. 多视图立体匹配 (MVS)：稠密化三维场景**

在通过SfM获得稀疏三维几何和相机姿态后，MVS算法旨在生成稠密的三维点云或表面网格 3。MVS利用已知的相机参数和极线几何约束，结合图像间的颜色或亮度一致性（光度一致性）来为每个像素或图像块找到密集的对应关系，从而恢复场景的稠密三维信息。

常见的MVS方法包括基于深度图融合的方法、基于体素的方法和基于面片的方法。其一般工作流程包括：

1. **深度/视差估计 (Depth/Disparity Estimation)**：为图像中的像素赋予深度值或计算视差图，通常通过三角化或块匹配等技术实现 3。  
2. **深度图优化/融合 (Depth Refinement/Fusion)**：对初始深度图进行优化，以确保平滑性和一致性，并融合来自多个视图的深度信息 3。  
3. **表面重建 (Surface Reconstruction)**：将优化后的深度图反投影回三维空间，生成稠密点云，进而可以构建三角网格等表面模型 3。

MVS面临的挑战主要在于处理遮挡、反射表面、无纹理区域，以及生成高分辨率输出时的高计算需求。MVS对于从倾斜摄影和无人机影像创建细节丰富且视觉完整的3D模型至关重要。

### **C. 同时定位与地图构建 (SLAM)：实时重建与跟踪**

SLAM是指传感器（如相机）在未知环境中移动时，同时估计自身姿态并构建环境地图的过程 14。SLAM的核心特点是其实时性。

SLAM系统的关键组成部分通常包括：

* **前端 (Frontend)**：负责处理传感器数据，进行特征提取与跟踪、运动估计（里程计）和局部地图构建。  
* **后端 (Backend)**：负责优化，包括闭环检测（识别之前访问过的区域以校正累积误差）和全局地图优化（如姿态图优化）。

根据所使用的主要传感器和数据处理方式，SLAM可以分为多种类型，如基于特征的方法、直接法、半直接法；视觉SLAM (VSLAM) 和视觉惯性SLAM (VINS，结合相机和惯性测量单元IMU的数据)。

SLAM技术的主要挑战包括：有效的闭环检测、单目SLAM中的尺度模糊性（即无法确定场景的绝对大小）、处理动态环境（场景中存在移动物体）、以及在移动平台上的计算资源限制。SLAM主要应用于单目视频的三维重建，但其概念也可用于处理连续的无人机影像数据。

### **D. 深度学习在三维重建中的应用：范式转变**

深度学习（DL）越来越多地被用于解决三维重建各个阶段的挑战 21。

深度学习在三维重建中的具体应用包括：

* **单目深度估计 (Monocular Depth Estimation)**：利用深度学习模型从单张图像预测深度图 21。这方面已从预测相对深度发展到预测具有真实尺度的度量深度（Monocular Metric Depth Estimation, MMDE）。  
* **特征匹配 (Feature Matching)**：学习更鲁棒的特征描述子和匹配器，例如LoFTR 28。  
* **端到端重建 (End-to-End Reconstruction)**：一些深度学习模型尝试直接从输入图像重建三维几何。  
* **语义理解 (Semantic Understanding)**：融合语义信息（如物体类别）以改进重建结果或进行场景理解。

深度学习方法面临的挑战包括对大规模高质量标注数据集的需求、对未见过场景的泛化能力以及模型的可解释性。深度学习对单目视频重建的影响尤为显著，同时也正在影响传统的SfM/MVS流程，例如通过提供学习到的特征匹配器或深度先验。

这些基础技术之间存在着紧密的相互依赖关系。SLAM系统通常在其后端集成类似SfM的光束法平差。MVS的性能高度依赖于SfM或SLAM提供的相机姿态的准确性。因此，一个领域的进步往往能惠及其他领域。深度学习并非一个孤立的类别，而是日益融入SfM、MVS和SLAM中，它可以替代传统组件（例如用学习到的特征检测器替代手工设计的检测器）或提供先验信息（例如用单目深度估计辅助MVS）。一些深度学习方法甚至致力于实现端到端的重建，有可能绕过传统的SfM/MVS流程。

所有这些技术的成功都高度依赖于输入图像的质量和特性，包括纹理、光照、重叠度、视点变化等，正如COLMAP的使用指南中所强调的 29。低质量的输入数据将直接导致重建效果不佳，无论算法本身多么先进。这强调了“输入决定输出质量”的原则。用户通常寻求的是“算法”，但在实践中，三维重建涉及的是一个由多个算法组成的*流程*。开源*软件*通常实现了这些流程。理解这些算法阶段之间的相互作用是有效选择和使用开源工具的关键。

**表1：核心三维重建技术对比**

| 技术 | 核心原理 | 优势 | 劣势 | 典型输入数据 | 主要开源算法/工具示例 |
| :---- | :---- | :---- | :---- | :---- | :---- |
| 运动恢复结构 (SfM) | 从多视图图像中估计相机姿态和稀疏三维点云 | 无需先验知识，可处理无序图像集 | 计算量大，对纹理敏感，易受重复模式影响，输出稀疏点云 | 图像序列 | COLMAP, OpenMVG, Meshroom (AliceVision) |
| 多视图立体匹配 (MVS) | 利用已知相机姿态和稀疏点云生成稠密三维模型 | 可生成稠密点云和表面网格，细节丰富 | 依赖SfM结果的准确性，对遮挡、反射、无纹理区域敏感，计算量大 | SfM输出+图像序列 | COLMAP, MVE, OpenMVS (集成于某些流程) |
| 同时定位与地图构建 (SLAM) | 实时估计传感器姿态并同时构建环境地图 | 实时性，适用于动态环境（部分算法），可用于导航和定位 | 累积误差（漂移），闭环检测挑战，单目尺度模糊，计算资源受限（移动端） | 视频流，图像序列+IMU | ORB-SLAM3, VINS-Mono, SLAM3R, GigaSLAM, Gaussian Splatting SLAM |
| 深度学习 (用于深度/重建) | 利用神经网络从数据中学习三维信息（如深度图、特征、端到端重建） | 可处理传统方法难以解决的问题（如无纹理区域的深度估计），可学习复杂先验知识 | 依赖大规模高质量训练数据，泛化能力可能受限，模型可解释性差，部分模型计算量大 | 单张/多张图像，视频流 | IOAR, MonSter (组件), MiDAS, Depth Anything, ZoeDepth 等 |

## **III. 基于倾斜摄影的开源三维重建**

### **A. 倾斜影像在三维建模中的特性与优势**

倾斜摄影是指相机光轴与铅垂线（天底方向）成一定角度进行拍摄的技术 3。与传统的垂直摄影相比，倾斜影像能够提供更丰富的地物几何与纹理信息。

其主要优势包括：

* **增强的几何信息**：倾斜影像能够捕捉到建筑物立面、桥梁侧面等垂直结构的细节，这在垂直摄影中是无法实现的 2。因此，倾斜影像对于构建完整和逼真的三维模型，尤其是在城市环境中，至关重要。  
* **改进的纹理采集**：能够获取物体侧面的纹理信息，使得最终模型更具真实感 3。  
* **提升非专业用户的可理解性**：由于倾斜影像的视角更接近人眼观察地物的习惯，因此其数据成果更易于非专业用户理解和判读 3。  
* **提高模型精度**：在无人机SfM工作流程中，结合倾斜影像与垂直影像能够显著提高最终点云的空间精度和准确度，减少系统误差（如“穹顶效应”）和数据空洞 11。研究表明，采用20°-35°的较大倾斜角可以显著提升模型的精度 11。

### **B. 核心算法与摄影测量工作流程**

处理倾斜影像以进行三维重建，主要依赖于成熟的摄影测量工作流程，并针对倾斜影像的特性进行调整。

* **航空三角测量 (Aerial Triangulation, AT)**：这是建立图像之间以及图像与地面控制之间几何关系的核心过程，对于精确的地理配准至关重要 31。其关键技术环节包括倾斜摄影数据获取、像控点的布设与测量、倾斜相机检校、航空三角测量计算本身、多角度影像的密集匹配、不规则三角网 (TIN) 的构建、TIN简化以及纹理自动映射等 31。  
* **SfM与MVS流程**：这些是处理倾斜影像的标准流程，与处理垂直影像类似，但需要特别考虑倾斜影像带来的多变的尺度和视角问题 3。流程通常包括特征提取、特征匹配、相机姿态估计、光束法平差以及后续的稠密点云或网格生成。  
* **多相机系统**：倾斜影像通常由搭载在航空平台上的多镜头相机系统（如五镜头相机）获取 3。处理来自此类系统的数据需要对整个相机组合体进行精确的标定。  
* **直接地理参照 (Direct Georeferencing)**：通常会集成GPS/GNSS和IMU数据，以获取精确的影像位置和姿态信息，从而支持高精度的直接地理参照 3。

### **C. 倾斜影像开源工具与库概览**

多种开源工具和库可用于处理倾斜影像数据，它们通常是通用的SfM/MVS解决方案，但也包括一些针对倾斜航空影像的专门工具。

* **通用SfM/MVS工具**：  
  * **COLMAP**：作为一个通用的SfM和MVS管线 37，COLMAP能够处理包括倾斜视图在内的多样化图像集。其标准工作流程包括特征提取、匹配、稀疏重建和稠密重建 29。然而，在处理大规模倾斜无人机影像时，COLMAP可能面临场景分区中图像选择不优以及稠密化过程主要依赖单视图约束等挑战 38。最佳实践包括仔细的图像采集策略和参数调整。  
  * **Meshroom (AliceVision)**：AliceVision是其底层的摄影测量框架 39，Meshroom则提供了图形用户界面。尽管Meshroom能够生成良好的几何模型 40，但根据用户讨论，其在没有地面控制点的情况下直接利用RTK数据进行地理配准的功能似乎有限，往往需要借助第三方软件 40。尽管如此，AliceVision本身是一个稳健的SfM/MVS流程 15。  
  * **OpenMVG**：一个多视图几何库，常用于SfM。可以通过集成学习到的特征（如LoFTR）来提升在倾斜视图中常见的弱纹理区域的性能 28。  
  * **MVE (Multi-View Environment)**：一个端到端的基于图像的几何重建流程，包括SfM、MVS和表面重建 43。目前处于维护模式。其在处理倾斜无人机影像时可能存在的局限性包括计算开销较大以及纹理映射方面的问题，如畸变和光照不一致 44。  
* **针对倾斜航空影像的专门库/框架**：  
  * **Deep3D\_Aerial**：一个基于深度学习的多视图立体匹配和三维场景重建的官方实现，专门针对倾斜航空影像 46。 (GitHub: gpcv-liujin/Deep3D\_Aerial)  
  * **FaSS-MVS**：一种快速的、表面感知的半全局优化MVS方法，专为从单目倾斜无人机影像中快速估计深度图和法线图而设计，支持在线三维建图 47。  
* **商业软件的工具包 (可能包含开源组件/脚本)**：  
  * **Agisoft-Oblique-Toolkit**：一系列Python脚本，用于辅助在Agisoft Metashape中处理航空倾斜影像数据（例如徕卡CityMapper数据），专注于足迹生成、引导图像匹配和多阶段图像对齐 48。 (GitHub: UAV-GeoLAB/Agisoft-Oblique-Toolkit, Apache-2.0许可证)。

### **D. 应用与性能考量**

倾斜摄影三维重建技术已广泛应用于多个领域：

* **应用领域**：包括三维城市建模 2、建筑物检测与损伤评估 31、电力设施识别与建模 36、地形测绘 33 以及文化遗产保护 51。  
* **精度**：在良好控制的项目中可以达到较高的精度，例如均方根误差（RMSE）可达厘米级 33。满足1:500比例尺地图的精度要求是可行的 35。  
* **挑战**：处理大规模数据集、确保大范围内的几何精度、处理遮挡以及在复杂立面上实现一致的纹理映射仍然是主要挑战。倾斜影像本身可能存在尺度变化、遮挡和光照不一致等问题，需要细致处理 52。

倾斜影像的独特性质，如对垂直表面的多视角观测和尺度变化，确实对处理算法提出了更高的要求。虽然通用的SfM/MVS工具可以处理倾斜影像，但为了充分发挥其优势（例如清晰的立面细节、精确的垂直几何），专门的算法或工作流程调整往往能带来更优的结果。Deep3D\_Aerial 46 和FaSS-MVS 47 等工具的出现，以及Agisoft-Oblique-Toolkit 48 这种为特定商业软件提供辅助的开源脚本，都反映了这一需求。

工具的“开放性”也呈现出多样化的特点。一些是完全开源的流程（如COLMAP、Meshroom），而另一些则是增强商业软件功能的开源脚本或插件（如Agisoft-Oblique-Toolkit之于Metashape）。这反映了利用开源贡献的不同策略。并非所有“开源解决方案”都是独立的应用程序；有些是对现有专有系统的补充。这是一种务实的方法，即核心商业软件提供稳健的基础，而开源附加组件则提供专业功能或自动化，例如Agisoft-Oblique-Toolkit 48 为Metashape提供的功能。这种方式可以在不重新发明整个轮子的情况下弥合差距或改进特定工作流程。

倾斜摄影三维模型的质量与采集策略（相机角度、重叠度、飞行模式）和后续处理（标定、AT、SfM-MVS）直接相关。研究 11 明确指出，采用较大的倾斜角（20-35°）和较高的重叠度可以提高精度。倾斜摄影旨在捕捉垂直表面的更多细节。如果角度过小或重叠不足，几何优势就会丧失，导致模型不完整或出现系统误差。随着倾斜摄影在城市建模等应用中日益普及，对标准化的开源工作流程和最佳实践的需求也日益增长，以确保输出结果的一致性和高质量，特别是在处理多相机系统和大规模数据集时。关于实用航空三角测量技术 31 和最佳成像角度 11 的研究正指向这一发展方向。

## **IV. 基于无人机影像的开源三维重建**

### **A. 无人机数据采集：高质量重建的基础**

无人机（UAV）数据采集的质量直接影响最终三维模型的精度和完整性。细致的规划和恰当的参数设置是成功的关键。

* **飞行规划 (Flight Planning)**：任务规划需综合考虑目标物体的几何形状、天气条件、光照、相机标定以及所用无人机的类型 1。通常使用地面站软件来设计飞行参数，如航高、速度、航线等 33。  
* **影像重叠度 (Image Overlap)**：对于稳健的SfM处理至关重要。典型的重叠度设置是航向重叠70-80%，旁向重叠60-70% 6。为了保证精度，通常推荐更高的重叠度，例如85% 5。较低的重叠度（如60-70%）可能导致模型变形 5。  
* **地面采样距离 (Ground Sampling Distance, GSD)**：GSD定义了图像中单个像素所代表的实际地面尺寸。较低的GSD（即更高的分辨率）通常能提供更丰富的细节，但同时也会增加数据量 5。针对屋顶设施评估的研究发现，0.75-1.26厘米的GSD范围与85%的影像重叠度相结合，可以在保证模型精度的同时，最大限度地减少采集的影像数量和飞行时间 5。GSD取决于飞行高度、相机焦距和传感器像元尺寸 4。  
* **倾斜无人机影像 (Oblique UAV Imagery)**：在无人机作业中，结合倾斜影像与垂直（Nadir）影像能够显著改善模型的精度，减少系统误差（如“穹顶效应”），并更好地覆盖垂直特征 11。采用20-35°的较大倾斜角通常更有利 11。特定的飞行模式，如围绕垂直航线外围飞行的“BoxO”模式或双重汇聚弧线模式，可以产生更高精度的结果 11。  
* **相机设置 (Camera Settings)**：关键参数包括焦距、光圈、曝光时间和ISO。为了减少模糊，通常选择较大的景深（即较小的光圈）；为了补偿光圈缩小导致的光线不足，宁可提高ISO也不宜增加曝光时间，以避免运动模糊 4。  
* **地理参照数据 (Georeferencing Data)**：利用GPS/GNSS模块为影像添加地理标签是标准做法 1。采用RTK（实时动态差分）或PPK（后处理动态差分）技术可以获得更高的定位精度，并可能减少对地面控制点（GCP）的依赖 34。

### **B. 无人机数据处理的主流SfM-MVS流程**

处理无人机影像以生成三维模型，主要遵循SfM-MVS的技术流程。

* **通用工作流程**：包括影像获取、影像对齐/特征匹配（寻找同名点）、SfM处理（相机姿态和稀疏点云生成）、光束法平差、MVS处理（稠密点云生成）、网格构建、纹理映射以及地理参照等步骤 1。  
* **核心算法**：SfM和MVS是整个流程的核心 1。  
* **软件实现**：众多开源和商业软件都实现了这一流程 15。

### **C. 无人机影像关键开源软件回顾**

针对无人机影像处理，已涌现出一批功能强大的开源软件。

* **OpenDroneMap (ODM) 和 WebODM**：  
  * **ODM**：一个命令行工具包，用于从无人机影像生成地图、点云、三维模型和数字高程模型（DEM）57。它使用OpenSfM 57 和可能的MVE（其GitHub仓库中存在MVE的分支 57）作为后端处理引擎。支持JPEG、TIFF、DNG等图像格式 58。  
  * **WebODM**：为ODM提供了用户友好的图形界面，支持多种处理引擎（ODM、MicMac）58。其功能包括生成正射影像、点云、高程模型、三维模型，进行量测、植被健康分析，支持GCP、等高线、卷帘快门校正、成果共享和可伸缩处理 60。相关文档也较为完善 58。  
  * **倾斜影像支持**：WebODM声称可以处理航空和地面影像，无论是垂直拍摄还是倾斜拍摄 60。  
* **COLMAP**：广泛应用于SfM和MVS领域 37。其教程详细介绍了从图像导入到稠密重建的完整工作流程 29。能够处理无人机数据集，包括倾斜影像，但大规模处理可能面临挑战 38。针对无人机数据的最佳实践包括保证良好的重叠度、多变的视点和一致的光照条件 29。COLMAP也被应用于协作式无人机测绘研究中 63。  
* **Meshroom (AliceVision)**：  
  * AliceVision是其核心摄影测量引擎 39，Meshroom是其图形用户界面。  
  * 适用于无人机影像处理；有评测表明，在处理大规模无人机影像方面，AliceVision在开源工具中具有较好的效率和完整性 15。  
  * 用户讨论指出，在没有GCP的情况下，其对RTK数据的地理参照功能有限 40，通常需要外部工具如CloudCompare辅助。但也有提及，若EXIF中包含WGS84格式的GPS信息，SfmTransform节点或许可以利用这些信息 40。  
* **MVE (Multi-View Environment)**：  
  * 一个端到端的重建流程，包括SfM、MVS和表面重建 43。目前处于维护模式。  
  * 在一些研究中被用于无人机影像处理 44。其挑战可能在于处理倾斜无人机数据时的计算开销和纹理映射质量 44。  
* **OpenMVG**：  
  * 一个SfM库，可用于无人机影像处理 28。与LoFTR等学习到的特征结合，有望改善在无人机数据中常见的弱纹理区域的处理效果 28。已被用于基于无人机倾斜影像的建筑物重建 42。  
* **ParallelSfM**：  
  * 专为大规模无人机影像（包括倾斜影像）的稀疏重建而设计 66。采用局部连接约束的边加权策略和无锚点的并行合并算法。(GitHub: json87/ParallelSfM)。  
* **基于深度学习的方法 (针对倾斜无人机影像)**：  
  * **Deep3D\_Aerial**：基于深度学习的MVS和三维重建方法，针对倾斜航空影像 46。(GitHub: gpcv-liujin/Deep3D\_Aerial)。  
  * **FaSS-MVS**：一种快速MVS方法，用于从单目倾斜无人机影像进行在线三维建图 47。

### **D. 无人机影像的特定挑战**

尽管无人机影像带来了便利，但在三维重建过程中也面临一些特有的挑战。

* **地理参照精度 (Georeferencing Accuracy)**：要保证高绝对精度，通常需要布设GCP或使用高质量的RTK/PPK数据 15。COLMAP和Meshroom在这方面的处理方式和局限性有所不同。  
* **大规模数据量 (Large Data Volumes)**：高分辨率影像和大范围测区会产生海量数据，给SfM/MVS的计算带来巨大压力 15。ParallelSfM 66 等工具旨在解决这一问题。  
* **倾斜无人机影像处理 (Processing Oblique UAV Imagery)**：需要鲁棒的算法来处理变化的尺度、视角以及潜在的遮挡问题 11。Deep3D\_Aerial 46 和FaSS-MVS 47 等软件专注于此。  
* **“穹顶效应”/系统误差 ("Bowl Effect" / Systematic Errors)**：在狭长廊道或相机网络几何不佳的情况下，尤其是在自标定时，容易出现此类系统误差 11。倾斜影像有助于缓解这一问题 11。  
* **无纹理或重复纹理表面 (Textureless or Repetitive Surfaces)**：在某些场景（如大片农田、水体、均质屋顶）中常见，对特征匹配构成挑战。

### **E. 在测绘、建图与巡检中的应用**

无人机三维重建技术已在众多行业得到广泛应用。

* **地形测绘与DEM/DSM生成**：11。  
* **城市规划与基础设施建设**：1。  
* **矿业、建筑业与土地调查**：用于土方量计算、矿坑监测、施工进度跟踪等 6。  
* **环境监测与灾害管理**：6。  
* **文化遗产数字化保护**：1。  
* **电力线路与设施巡检**：36。无人机倾斜摄影被用于杆塔重建 36。对于电力线这类细小结构，点云可能不完整且充满噪声，构成挑战 71。  
* **屋顶基础设施评估**：5。  
* **林分分析/碳汇恢复**：单木分割、参数提取 34（使用大疆Mavic3和DJI Smart Map）。  
* **生物多样性保护/野生动物研究**：栖息地测绘 63。COLMAP被用于此领域的协作式无人机测绘。

无人机影像的采集参数（重叠度、GSD、倾斜角等）与重建质量之间存在着至关重要的相互作用。多项研究 5 强调了优化这些参数的重要性，它们直接导致模型精度和完整性的显著差异。这并非微不足道的调整，而是基础性的环节。SfM/MVS算法依赖于充分、高质量且具有几何多样性的视觉信息。重叠度不足意味着可供匹配的同名特征减少，导致几何连接薄弱，可能引发模型破碎或变形 5。不恰当的GSD会影响可分辨的细节。缺乏倾斜视角则会导致“穹顶效应”等系统误差 11。因此，采集策略是决定输出质量的首要因素，其影响往往超过成熟SfM算法之间的微小差异。

开源无人机处理领域正在走向成熟，但仍在地理参照和可伸缩性方面面临挑战。像ODM/WebODM这样的工具提供了用户友好的操作界面，而COLMAP/Meshroom等库则提供了强大的核心引擎。然而，与某些商业解决方案相比，无缝、高精度的地理参照（尤其是在没有大量GCP情况下的RTK应用）以及对海量数据集的高效处理，仍然是开源解决方案持续发展的领域 15。用户讨论 40 和对比评测 41 指出，在Meshroom等工具中直接进行精确地理参照存在不便。处理*超大规模*无人机数据集的可伸缩性是SfM面临的已知挑战 15，尽管存在像ParallelSfM 66 这样的解决方案，但它们可能尚未完全集成到用户友好的平台中。

在无人机工作流程中采用倾斜影像是对仅有垂直影像的几何局限性的直接回应，特别是在捕捉垂直结构和减少模型变形方面 11。这推动了多镜头无人机相机系统 33 和专门处理技术（如Deep3D\_Aerial 47, FaSS-MVS 46）的发展。垂直影像擅长生成2.5D产品，但在真三维表达方面，尤其是对建筑物而言，则显得力不从心。倾斜视图提供了缺失的侧面信息。这一需求催生了硬件创新（多镜头相机）和软件创新（更适合处理倾斜视图或垂直-倾斜组合数据集的算法）。

尽管通用的SfM/MVS流程具有普适性，但无人机数据的多样化应用（例如电力线路巡检 36、林业 34、屋顶评估 5）正催生出更多针对特定领域独特特性和精度要求的专业化开源工具、算法或最佳实践指南。这预示着未来用户可能会从一套开源组件中进行选择，为特定的无人机应用构建优化的处理流程。

**表2：倾斜与无人机摄影测量主要开源软件**

| 软件 | 主要算法 | 倾斜影像支持 | 无人机影像支持 | 主要特性 | 优势 | 已知局限/挑战 | GitHub/项目链接 |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| COLMAP | SfM, MVS | 是 | 是 | GUI, CLI, 多种匹配模式, 稠密重建 | 通用性强, 精度较高, 社区活跃 | 大规模数据处理可能较慢, 倾斜影像分区选择和稠密化有待优化 | [https://github.com/colmap/colmap](https://github.com/colmap/colmap) |
| Meshroom (AliceVision) | SfM (AliceVision), MVS (AliceVision) | 是 | 是 | GUI, 节点式流程 | 开源, 流程直观, AliceVision引擎稳健, 在开源工具中效率和完整性较好 | 直接RTK地理参照功能有限 (需外部工具或特定EXIF格式), 点云密度可能低于商业软件 | [https://github.com/alicevision/Meshroom](https://github.com/alicevision/Meshroom) |
| OpenDroneMap (ODM) / WebODM | SfM (OpenSfM), MVS (OpenSfM, MVE-fork) | 是 (WebODM明确支持) | 是 | WebODM: GUI, 用户友好, 多引擎; ODM: CLI, 可扩展 | 易用性 (WebODM), 完整流程, 支持GCP, 多种输出格式 | 精度和效率可能因后端引擎和参数调整而异 | (https://github.com/OpenDroneMap) |
| MVE (Multi-View Environment) | SfM, MVS, Surface Reconstruction | 是 (通用) | 是 (通用) | CLI, UMVE查看器 | 端到端流程, 针对多尺度场景设计 | 维护模式, 计算开销可能较大, 纹理映射对倾斜影像的挑战 | [https://github.com/simonfuhrmann/mve](https://github.com/simonfuhrmann/mve) |
| OpenMVG | SfM | 是 (通用) | 是 (通用) | CLI, 库 | 模块化, 可与其他MVS结合, LoFTR等增强可提高弱纹理区性能 | 主要集中于SfM, 完整流程需配合其他工具 | [https://github.com/openMVG/openMVG](https://github.com/openMVG/openMVG) |
| ParallelSfM | 并行SfM | 是 (针对大规模UAV) | 是 (针对大规模UAV) | CLI, 针对大规模数据优化 | 高效处理大规模UAV影像, 支持倾斜数据 | 专注于稀疏重建, 流程集成度可能不如完整套件 | ([https://github.com/json87/ParallelSfM](https://github.com/json87/ParallelSfM)) |
| Deep3D\_Aerial | 深度学习 MVS | 是 (专门针对) | 是 (专门针对倾斜航空) | Python框架 | 针对倾斜航空影像的深度学习优化 | 依赖深度学习环境和训练数据 (或预训练模型) | ([https://github.com/gpcv-liujin/Deep3D\_Aerial](https://github.com/gpcv-liujin/Deep3D_Aerial)) |
| FaSS-MVS | 快速MVS | 是 (专门针对单目倾斜) | 是 (专门针对单目倾斜) | C++实现 | 快速, 表面感知, 支持在线建图 | 专注于MVS阶段, 精度可能略低于某些离线方法 | (论文提及, 需查找代码库) |

## **V. 基于单目视频的开源三维重建**

### **A. 内在挑战：单目视觉的困境**

从单目视频（即单个移动相机拍摄的连续图像帧）进行三维重建面临一系列独特的挑战，这些挑战源于缺乏直接的深度信息和双目视觉的几何约束。

* **尺度模糊性 (Scale Ambiguity)**：这是单目视觉的一个根本问题。仅从单目视频本身无法确定重建场景的绝对尺寸和相机运动的真实尺度，除非有外部信息（如已知尺寸的物体、IMU数据或相机高度等）作为参考 14。  
* **动态场景 (Dynamic Scenes)**：传统的SfM和SLAM算法通常假设场景是静态的。如果场景中存在移动物体，会导致跟踪失败或错误的几何重建 8。处理动态场景需要采用分段刚性模型、物体分割或专门的动态SLAM方法 8。  
* **实时性约束 (Real-Time Constraints)**：许多应用场景，如机器人导航、增强现实（AR）和虚拟现实（VR），都要求实时的姿态估计和地图构建 4。  
* **初始化 (Initialization)**：启动重建过程，即估计初始的相机姿态和三维点，对于单目系统而言可能非常具有挑战性，因为它依赖于足够的视差和可靠的特征匹配。  
* **漂移 (Drift)**：在处理长视频序列时，由于里程计误差的不断累积，会导致估计的相机轨迹和地图逐渐偏离真实情况。闭环检测（识别并重新定位到先前访问过的区域）对于校正漂移至关重要 14。

### **B. 开源SLAM系统：同步导航与建图**

SLAM技术是解决单目视频三维重建和相机跟踪的关键。众多开源SLAM系统为研究和应用提供了强大的工具。

#### **1\. 传统基于特征/直接法的SLAM**

* **ORB-SLAM3**：这是一个功能全面且精度较高的开源库，支持基于单目、双目和RGB-D相机的视觉SLAM、视觉惯性SLAM以及多地图SLAM 20。其针对单目相机的版本表现出色。关键创新点包括鲁棒的IMU初始化方法和多地图系统，后者使其能够在跟踪丢失后继续工作并在重访旧区域时无缝合并地图。ORB-SLAM3以其高精度著称。(GitHub: UZ-SLAMLab/ORB\_SLAM3)  
* **VINS-Mono**：一个鲁棒的实时单目视觉惯性SLAM框架 13。它采用基于优化的滑动窗口方法，实现了高效的IMU预积分（带有偏差校正）、自动初始化、在线外参标定、故障检测与恢复、闭环检测以及全局姿态图优化。VINS-Mono主要为无人机和AR应用设计。(GitHub: HKUST-Aerial-Robotics/VINS-Mono)

#### **2\. 近期基于学习和混合型SLAM**

近年来，深度学习与传统几何方法的结合，以及新的场景表示方法（如高斯溅射），为单目SLAM带来了新的突破。

* **Gaussian Splatting SLAM**：这是一种新颖的方法，利用三维高斯溅射（3D Gaussian Splatting）技术从单目（或RGB-D）视频进行增量式三维重建，据称能以约3帧/秒的速度实时运行 16。其特点是直接针对三维高斯进行优化以实现相机跟踪，并引入几何验证来处理增量式稠密重建中的模糊性。该方法甚至能够重建微小或透明的物体。  
* **SLAM3R**：一个能以超过20帧/秒的速度从单目RGB视频进行实时稠密三维重建的系统 17。它采用前馈神经网络分别进行局部重建（图像到点云）和全局配准（局部到世界），无需显式求解相机参数。(GitHub: PKU-VCL-3DV/SLAM3R)  
* **GigaSLAM**：专为大规模无界室外环境设计的单目SLAM系统，采用分层高斯溅射表示场景 18。它结合了度量深度模型、PnP算法进行姿态估计，并使用基于词袋模型的闭环检测机制。GigaSLAM能够处理公里级别的室外环境。  
* **MASt3R-SLAM**：一个实时的（15帧/秒）稠密SLAM系统，它利用MASt3R（一种双视图三维重建和匹配先验）处理单目视频 19。该系统支持动态变化的相机模型。

### **C. 深度学习在单目深度估计与重建中的应用**

深度学习在克服单目视觉固有挑战方面发挥了越来越重要的作用，尤其是在深度估计和场景理解方面。

* **单目深度估计 (MDE & MMDE)**：  
  * 深度学习模型能够从单张图像预测深度信息 21。  
  * **单目度量深度估计 (MMDE) 的进展**：旨在克服尺度模糊性，预测具有绝对物理尺度的深度。主要挑战包括对新环境的泛化能力和物体边界的模糊问题 23。近期的模型如MiDAS、Depth Anything、ZoeDepth以及基于生成模型的方法（如Marigold、GeoWizard、DMD）在此方面取得了显著进展 78。这些模型的开源实现对于推动研究至关重要。  
* **基于体素的重建方法**：  
  * **IOAR (Inner-Outer Aware Reconstruction)**：一种由粗到精的策略，将体素分为外表面、内表面和表面三类，从而提高从单目RGB序列重建的网格精度 7。(代码: YorkQiu/InnerOuterAwareReconstruction)  
* **混合方法 (深度学习 \+ 传统方法)**：  
  * **MonSter**：该方法将单目深度估计（如使用DepthAnythingV2）和双目立体匹配（如使用IGEV）集成到一个双分支架构中，通过立体引导对齐（SGA）和单目引导优化（MGR）模块进行迭代式相互增强，以改善三维重建效果，尤其是在病态区域（如遮挡、弱纹理）22。如果其使用的核心模型是开源的，则该方法的部分或全部组件也可能是开源的。  
* **自监督学习 (Self-Supervised Learning)**：无需地面真值深度图，利用视频中的时序信息或其他约束来训练深度模型 25。有研究提出了针对倾斜无人机视频的自监督深度估计架构，采用两个2D CNN编码器和一个3D CNN解码器，并引入了对比损失项 25。

### **D. 开源实现的可用性与能力**

将上述讨论的SLAM系统和深度学习模型与其各自的GitHub存储库（如ORB-SLAM3、VINS-Mono、SLAM3R、IOAR、GigaSLAM以及MASt3R-SLAM的可用组件）相关联是非常重要的。这些开源项目的成熟度、社区支持的活跃程度以及文档的完善性，都直接影响着它们在研究和实践中的可用性。

单目重建领域的发展表明，尽管通用的、无约束的单目重建仍然非常困难，但由于深度学习和视觉惯性SLAM的进步，特定领域的单目重建问题正日益得到解决。视觉惯性SLAM（如VINS-Mono, ORB-SLAM3）和近期的基于深度学习的SLAM/深度估计方法（如SLAM3R, GigaSLAM, MMDE模型）展现出了非凡的鲁棒性和准确性，尤其是在有IMU数据辅助或针对特定任务（如GigaSLAM 18 关注的自动驾驶场景，基于KITTI数据集）时。尺度模糊性曾是主要障碍，IMU提供了度量尺度信息 14，而深度学习模型则能非常有效地学习场景尺度或相对深度的先验知识 78。这种结合使得单目系统在许多机器人和AR应用中变得实用。从纯几何方法到学习增强几何方法的转变是这一成功的关键。

早期的SLAM主要关注稀疏地图的构建。如今，像SLAM3R 17、MASt3R-SLAM 74 和Gaussian Splatting SLAM 16 这样的系统，则致力于从单个相机实时生成稠密、高保真度的重建结果。这在能力上是一个显著的飞跃。稀疏地图适用于定位，但稠密地图对于交互、在杂乱空间中导航以及逼真的AR体验更为必要。现代GPU的计算能力以及算法创新（如高斯等神经表示方法、高效融合技术）正在使这成为可能。这一趋势弥合了传统SLAM（侧重定位）和MVS（离线稠密建模）之间的差距。

许多前沿的单目方法（如IOAR 7、SLAM3R 73 以及在 23 中讨论的MMDE模型）都伴随着开源代码，并依赖于公开数据集（如ScanNet、TUM-RGBD、KITTI）。这种开放的方式加速了研究和基准测试。深度学习研究的繁荣离不开共享的代码和数据。像DepthAnythingV2 22 这样的预训练组件的可用性，使得研究人员能够构建更复杂的系统，如MonSter。公开的基准测试则允许进行公平比较并推动进步。这种开放的生态系统是单目深度估计和SLAM领域快速发展的直接原因。随着开源单目重建算法变得越来越强大和鲁棒，普通的单个相机（存在于数十亿设备中）正成为执行复杂三维感知任务的日益可行的传感器，从而降低了AR、机器人和自主系统的入门门槛。对动态相机模型的研究（如MASt3R-SLAM 74）进一步拓宽了其适用性。

**表3：主要的单目视频开源SLAM系统**

| 系统 | SLAM类型 | 主要特性 | 实时性能 (报告FPS) | 尺度/动态处理 | 优势 | 已知局限 | GitHub/项目链接 |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| ORB-SLAM3 | 基于特征, 视觉惯性 (V-I) | 闭环检测, 多地图, 支持IMU, 稀疏/半稠密 | 实时 (具体取决于硬件) | IMU解决尺度, 多地图处理动态/跟踪丢失 | 高精度, 鲁棒性强, 功能全面 | 稠密建图非主要目标, 计算资源要求较高 | ([https://github.com/UZ-SLAMLab/ORB\_SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3)) |
| VINS-Mono | 基于优化, 视觉惯性 (V-I) | IMU预积分, 闭环检测, 在线外参标定, 稀疏 | 实时 | IMU解决尺度 | 鲁棒, 高精度VIO, 适用于无人机/AR | 稀疏地图, 对剧烈运动敏感 | ([https://github.com/HKUST-Aerial-Robotics/VINS-Mono](https://github.com/HKUST-Aerial-Robotics/VINS-Mono)) |
| Gaussian Splatting SLAM | 基于高斯溅射, 学习辅助 | 增量式稠密重建, 直接优化跟踪 | \~3 FPS | 几何验证处理模糊性 | 可重建微小/透明物体, 新颖的场景表示 | 实时性能较低, 相对较新的方法, 可能不如传统方法成熟 | 16 |
| SLAM3R | 基于深度学习, 端到端 | 实时稠密重建, 无显式相机参数求解 | 20+ FPS | 学习到的先验可能有助于处理尺度和动态 (需进一步确认) | 实时稠密重建, 端到端学习 | 依赖训练数据和模型泛化能力 | ([https://github.com/PKU-VCL-3DV/SLAM3R](https://github.com/PKU-VCL-3DV/SLAM3R)) |
| GigaSLAM | 基于高斯溅射, 学习辅助, 大规模 | 分层高斯溅射, 度量深度模型, BoW闭环, 室外公里级 | 实时 (具体取决于硬件) | 度量深度模型处理尺度, 针对室外大规模场景 | 适用于大规模无界室外环境, 高保真渲染 | 复杂性高, 计算资源要求可能较高 | 18 |
| MASt3R-SLAM | 基于学习先验 (MASt3R), 稠密 | 利用双视图重建先验, 支持动态相机模型 | 15 FPS | 支持动态相机模型, MASt3R先验可能有助于尺度 | 针对野外视频序列的鲁棒性, 无需固定或参数化相机模型 | 依赖MASt3R先验的质量和泛化能力 | 74 |

**表4：部分用于单目三维重建/深度估计的开源深度学习方法**

| 方法/模型 (示例) | 核心概念 | 输入 | 输出 (深度图, 三维网格, 点云) | 主要创新点 | 报告性能亮点/目标应用 | GitHub/论文链接 (若代码可用) |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| IOAR | 体素分类 (外表面, 内表面, 表面) | 单目RGB序列 | 三维网格 | 新的由粗到精策略, 分离占据分支和TSDF分支 | 在ScanNet等数据集上提升网格精度 | ([https://github.com/YorkQiu/InnerOuterAwareReconstruction](https://github.com/YorkQiu/InnerOuterAwareReconstruction)) |
| MonSter (组件) | 单目深度与立体匹配融合 | 立体图像对 | 深度图 | 双分支架构, 迭代相互增强 (SGA, MGR) | 在病态区域显著提升立体匹配效果 | (依赖其使用的DepthAnythingV2, IGEV等开源组件, MonSter本身代码需查找) |
| MiDAS | 相对深度估计, 多数据集训练 | 单张RGB图像 | 相对深度图 | 零样本跨域泛化能力强 | 通用相对深度估计 | ([https://github.com/isl-org/MiDaS](https://github.com/isl-org/MiDaS)) |
| Depth Anything / V2 | 大规模自监督学习/合成数据训练 | 单张RGB图像 | 相对/度量深度图 | 强大的零样本泛化能力, V2提升细节 | 通用深度估计, V2注重度量和细节 | ([https://github.com/LiheYoung/Depth-Anything](https://github.com/LiheYoung/Depth-Anything)) |
| ZoeDepth | 度量深度估计, 自适应度量分箱 | 单张RGB图像 | 度量深度图 | 零样本度量深度估计, 跨域泛化 | 精确的绝对尺度深度估计 | ([https://github.com/isl-org/ZoeDepth](https://github.com/isl-org/ZoeDepth)) |
| 25中自监督模型 | 2D CNN编码器 \+ 3D CNN解码器, 对比损失 | 连续视频帧 | 逆深度图 | 针对倾斜无人机视频的自监督单目深度估计 | 在UAVid数据集上优于SOTA | (论文提及架构, 需查找代码库) |

## **VI. 对比分析与实践指南**

### **A. 开源工具特性对比**

选择合适的三维重建开源工具需要综合考虑多个因素。

* **易用性**：对于初学者或希望快速得到结果的用户，带有图形用户界面（GUI）的工具如WebODM、Meshroom和COLMAP GUI版本通常更受欢迎。而命令行界面（CLI）工具虽然学习曲线较陡，但更适合批处理和集成到自动化流程中。软件的安装便捷性、设置的复杂度以及文档的质量也是衡量易用性的重要指标 9。  
* **可伸缩性**：处理大规模数据集（如数千张无人机影像 15 或长时视频序列）对工具的计算效率和内存管理能力提出了很高要求。一些工具如ParallelSfM 66 和GigaSLAM 18 专门为大规模数据处理而设计。  
* **精度**：精度是衡量重建质量的核心指标。需要区分相对精度（模型内部几何一致性）和绝对精度（模型在真实世界坐标系中的准确性，即地理参照精度）。基准测试和研究论文中的精度报告（如 5）可以提供参考。  
* **鲁棒性**：指工具在各种挑战性条件下的表现，例如处理无纹理区域、光照变化剧烈或包含动态元素的场景。  
* **社区支持**：活跃的GitHub代码库、及时响应的问题跟踪、丰富的教程和用户论坛，这些都是衡量一个开源项目健康度和可持续性的重要标志 9。  
* **许可证**：不同的开源许可证（如OpenCV的Apache 2许可证 9，COLMAP的BSD许可证 37，ODM的AGPL许可证 57）对软件的使用、修改和分发有不同的规定，用户需要了解其具体含义。

目前并不存在一个能够完美适用于所有场景的“万能”开源解决方案。工具的选择在很大程度上取决于输入数据的模态、期望的输出（稀疏/稠密点云、是否需要地理参照、是否需要实时处理）、用户可用的专业知识以及计算资源。例如，需要从无人机数据快速生成正射影像的用户可能会选择WebODM，因为它易于使用。而开发新MVS算法的研究人员可能会使用COLMAP的命令行界面以进行细致的控制。需要实时位姿估计的机器人工程师则会关注SLAM系统。这种多样性是开源生态系统的一大优势，但也要求用户进行仔细的选择。

开源工具与商业软件一样，通常需要在速度、精度和鲁棒性之间进行权衡。例如，用户在讨论中提到COLMAP相对于RealityCapture在速度上的不足 80。实时SLAM系统为了保证速度，可能会在全局地图精度方面做出一些牺牲，而离线的批处理SfM/MVS则可以投入更多时间以获得更高精度。高精度的MVS过程本身可能非常耗时。用户在选择工具时需要理解这些固有的权衡。

一个开源项目能否得到广泛应用和持续改进，很大程度上取决于其社区的活跃程度和文档的完善程度。那些积极维护、拥有良好文档并且社区响应迅速的项目（如COLMAP、OpenCV、ODM）往往更容易被用户接受和贡献，从而形成一个积极的反馈循环。如果一个工具难以安装、文档糟糕，或者对bug修复没有支持，即使用户认为其底层算法是合理的，也可能会放弃使用。成功的开源项目会在这些方面投入精力，从而培养更大的用户和开发者基础，进而带来更多的贡献和改进。

### **B. 特定三维重建任务的工作流程建议**

根据不同的应用需求，可以推荐以下基于开源工具的工作流程：

* **大规模城市建模 (倾斜/无人机影像)**：可考虑使用COLMAP、Meshroom或OpenDroneMap。为了更好地处理倾斜影像的特性，可以结合专门的倾斜影像处理工具（如Deep3D\_Aerial, FaSS-MVS）或效率提升工具（如ParallelSfM）。地理参照是此类应用的关键环节。  
* **精细立面/建筑物检测 (倾斜/无人机影像)**：与城市建模类似，但更侧重于高分辨率MVS和纹理质量。针对倾斜影像的专门工具尤为重要。  
* **地形测绘 (无人机影像)**：OpenDroneMap/WebODM和COLMAP是常用的选择。为了保证精度，GCP或高质量RTK数据的使用非常重要 33。  
* **实时机器人导航/AR (单目视频)**：对于鲁棒的姿态估计，可选择VINS-Mono或ORB-SLAM3。如果需要稠密地图，SLAM3R、GigaSLAM、MASt3R-SLAM或Gaussian Splatting SLAM等是值得考虑的方案。  
* **单目视频的离线重建 (如用于视觉特效、分析)**：可以使用COLMAP处理视频帧进行SfM/MVS重建。基于深度学习的深度估计算法（如IOAR, MonSter）可以用于增强几何细节。

### **C. 利用开源方法融合不同来源的数据**

融合来自倾斜摄影、无人机和单目视频等不同来源的数据，对于构建更完整、更精确的三维场景具有巨大潜力，但也面临挑战。有研究致力于融合地面和航空影像以重建城市复杂场景 12，开源的SfM和配准工具可以为此类融合提供支持。UseGeo数据集 24 提供了无人机影像和LiDAR数据，并带有地面真值深度信息，为融合算法的研究和验证提供了宝贵资源。

尽管用户查询的重点是“算法”，但其实用价值最终体现在其在可用、文档完善且具有合理效率的开源软件中的实现。本报告必须弥合理论算法与其在现实世界软件中的体现之间的差距。

## **VII. 开源三维重建的最新进展与未来方向**

开源三维重建领域正经历着快速发展，尤其受到人工智能和社区协作的推动。

### **A. 神经辐射场 (NeRF) 与高斯溅射 (Gaussian Splatting) 在开源领域的兴起**

神经辐射场 (NeRF) 和三维高斯溅射 (3DGS) 作为新兴的视图合成和场景表示技术，正越来越多地应用于SLAM和三维重建领域 16。这些技术能够以高保真度表示复杂场景。一些基于这些技术的开源实现或研究成果已经出现，例如GigaSLAM、Gaussian Splatting SLAM，以及用于城市倾斜航空影像重建的ULSR-GS 38。然而，它们在大场景的可伸缩性、训练时间以及几何精度与照片真实感之间的平衡等方面仍面临挑战 82（该文献比较了NeRF与MVS在航空影像上的表现，发现NeRF在完整性和细节方面更优，但在精度上仍有不足）。神经表示方法正在重塑三维重建领域。传统MVS生成显式的几何模型（网格、点云），而NeRF/3DGS学习隐式或显式的神经表示，非常适合渲染。目前的研究趋势是将这些技术应用于几何任务和实时SLAM（如GigaSLAM 18，Gaussian Splatting SLAM 16）。这是从纯几何流程向神经增强流程的范式转变。

### **B. 实时协作式建图**

利用多个无人机或智能体进行协作，以实现更快、更全面的地图构建，是当前的一个研究热点 63。一些开源框架或研究（例如基于COLMAP组件的OtF-SfM，以及CCM-SLAM 65）正在探索协作式SfM/SLAM。实时性能、设备端处理（如VINS-Mobile 13）以及协作式建图 65 等“前沿”需求正在推动技术进步，这些进步通常首先在开源社区中进行原型设计和共享。机器人、自动驾驶汽车和AR/VR等应用场景要求实时处理，并且通常需要在资源受限的设备上运行。这推动了对更高效算法和实现的研究，这些研究成果频繁地以开源项目的形式出现，以加速开发和应用。

### **C. 深度学习的深度融合**

深度学习的应用已超越了单纯的深度估计。学习到的特征描述子和匹配器（如LoFTR 28，SuperPoint/LightGlue 65）、利用语义分割辅助重建以及端到端的学习流程等，都在不断涌现。自监督和无监督学习方法旨在减少对大规模标注数据集的依赖 25。大规模公共数据集（如UseGeo 24）的可用性以及日益强大（且易于获取）的GPU，是深度学习在三维重建领域快速发展的直接推动力。深度学习模型对数据有很高的需求，没有大规模、多样化的数据集，它们就无法有效地学习。训练这些模型也需要大量的计算能力。数据集的开放共享和GPU的普及使得深度学习研究更加大众化，从而带来了在单目深度估计、学习特征等方面所见的突破。

### **D. 大规模多样化数据集的角色**

像UseGeo 24 这样包含无人机影像、LiDAR数据以及地面真值深度信息的数据集，对于训练和验证开源算法，尤其是基于深度学习的算法，至关重要。其他基准数据集，如用于单目重建的ScanNet、ICL-NUIM、TUM-RGBD 7，以及用于SLAM的KITTI 18，也发挥着重要作用。

### **E. 开源领域地理参照与传感器融合的改进**

在开源SfM/SLAM中，通过GPS/IMU进行直接地理参照，以减少对GCP的依赖，仍然是持续努力的方向。同时，在开源流程中更好地融合视觉数据与其他传感器（如LiDAR、IMU）数据也是一个重要趋势（例如VINS-Mono 13）。有研究提及将倾斜摄影与LiDAR结合用于电力线检测 49，以及利用无人机LiDAR进行电力线三维可视化 70，还有融合地面和航空影像的研究 12。

未来的开源工具可能会更加“智能化”，利用深度学习自动选择最佳参数、处理具有挑战性的数据、融合来自多个传感器/模态的信息，甚至对重建的场景进行语义解释。这将使强大的三维重建技术能够被更广泛的用户所接受，并减少手动干预。

## **VIII. 结论与战略建议**

### **A. 主要发现概要**

本报告对基于倾斜摄影、无人机影像和单目视频的开源三维重建算法进行了深入研究。总结而言：

* **倾斜摄影**：通过提供物体侧面信息，显著增强了三维模型的完整性和真实感，尤其适用于城市建模和精细结构重建。开源工具如COLMAP、Meshroom等可处理倾斜影像，但需注意其特定配置和潜在的地理参照挑战。  
* **无人机影像**：作为一种灵活高效的数据获取平台，无人机结合SfM-MVS流程已成为三维测绘的主流方法。OpenDroneMap、COLMAP等开源工具为此提供了支持，但大规模数据处理和高精度地理参照仍是关键。飞行参数的优化对模型质量至关重要。  
* **单目视频**：尽管面临尺度模糊和动态场景等挑战，但在实时SLAM和深度学习的推动下，单目三维重建取得了长足进步。ORB-SLAM3、VINS-Mono等传统SLAM系统以及SLAM3R、GigaSLAM等新兴的基于学习的系统，结合MMDE等深度估计算法，为机器人、AR等应用提供了可行的解决方案。  
* **核心技术与趋势**：SfM、MVS和SLAM是构建三维模型的基础。深度学习正深刻地改变着这些领域，从改进特定模块（如特征匹配、深度估计）到实现端到端重建。神经表示方法（如NeRF、高斯溅射）也显示出巨大潜力。  
* **开源生态**：开源社区提供了丰富的算法和工具，加速了技术创新和应用普及。然而，工具选择、易用性、可伸缩性和文档完善度等方面仍存在差异。

开源生态系统既呈现出碎片化，又表现出协同性。存在许多工具，有些功能重叠，有些则互为补充。这可能会让用户感到困惑，但也允许灵活地“混合搭配”构建流程。协同性体现在像OpenCV这样的库被许多工具所使用，或者一个工具的输出（例如COLMAP的稀疏重建结果）可以作为另一个工具（例如MVS或深度学习优化）的输入。

### **B. 对研究人员的建议**

* **探索前沿领域**：鼓励在鲁棒的多源数据融合、实时稠密的神经SLAM、无监督深度学习方法以及标准化的倾斜影像处理流程等方向进行更深入的研究。  
* **贡献开源社区**：积极参与现有开源项目的贡献（代码、文档、测试），或开发新的、文档完善的工具，以惠及整个社区。  
* **推动基准测试与数据集共享**：建立标准化的基准测试平台和共享更多样化、高质量的数据集，对于评估和比较不同算法的性能至关重要。

### **C. 对从业人员的建议**

* **明智选择工具**：根据具体的项目需求（精度、规模、实时性、输入数据类型、可用专业知识等）仔细评估和选择合适的开源工具。  
* **重视数据采集**：深刻理解数据采集的最佳实践，因为输入数据的质量直接决定了最终重建结果的上限。  
* **构建优化流程**：针对常见的重建任务，可以考虑结合不同开源组件的优势，构建定制化的工作流程。  
* **利用社区资源**：积极利用开源社区提供的论坛、教程等资源，解决实践中遇到的问题并学习新的技术。

### **D. 对开源三维重建未来的展望**

开源三维重建领域充满活力，预计在人工智能和社区协作的驱动下将继续快速发展。随着算法的不断进步和工具的日益成熟，开源解决方案将在推动三维视觉技术的创新和普及方面发挥越来越重要的作用。然而，为了更好地服务用户和开发者，开源生态系统在工具集成和基准测试方面仍有提升空间。目前，用户常常难以在众多开源选项中做出选择，或者难以构建复杂的流程。更模块化、数据格式兼容性更好的工具，以及清晰、公正的基准测试，将极大地改善这一状况。这是整个社区可以共同努力改进的领域。未来的趋势将是更加自主化和智能化的重建系统，从而使强大的三维重建技术能够被更广泛的受众所掌握，并减少人工干预。

#### **引用的著作**

1. personales.upv.es, 访问时间为 五月 19, 2025， [https://personales.upv.es/thinkmind/dl/conferences/sensordevices/sensordevices\_2021/sensordevices\_2021\_1\_60\_28032.pdf](https://personales.upv.es/thinkmind/dl/conferences/sensordevices/sensordevices_2021/sensordevices_2021_1_60_28032.pdf)  
2. www.jouav.com, 访问时间为 五月 19, 2025， [https://www.jouav.com/blog/oblique-imagery.html\#:\~:text=Oblique%20images%20offer%203D%20information,city%20model%20can%20be%20generated.](https://www.jouav.com/blog/oblique-imagery.html#:~:text=Oblique%20images%20offer%203D%20information,city%20model%20can%20be%20generated.)  
3. bibliotekanauki.pl, 访问时间为 五月 19, 2025， [https://bibliotekanauki.pl/articles/24988466.pdf](https://bibliotekanauki.pl/articles/24988466.pdf)  
4. (PDF) REAL-TIME 3D RECONSTRUCTION FROM IMAGES TAKEN ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/283184362\_REAL-TIME\_3D\_RECONSTRUCTION\_FROM\_IMAGES\_TAKEN\_FROM\_AN\_UAV](https://www.researchgate.net/publication/283184362_REAL-TIME_3D_RECONSTRUCTION_FROM_IMAGES_TAKEN_FROM_AN_UAV)  
5. arxiv.org, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2504.02084v1](https://arxiv.org/html/2504.02084v1)  
6. Drone for 3D Modeling: The Future of Aerial Mapping and ..., 访问时间为 五月 19, 2025， [https://ideaforgetech.com/blogs/drone-for-3d-modeling-how-uav-mapping-is-redefining-precision-design](https://ideaforgetech.com/blogs/drone-for-3d-modeling-how-uav-mapping-is-redefining-precision-design)  
7. proceedings.neurips.cc, 访问时间为 五月 19, 2025， [https://proceedings.neurips.cc/paper\_files/paper/2023/file/27c852e9d6c76890ca633f111c556a4f-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2023/file/27c852e9d6c76890ca633f111c556a4f-Paper-Conference.pdf)  
8. Video Pop-up: Monocular 3D Reconstruction of Dynamic Scenes, 访问时间为 五月 19, 2025， [http://www0.cs.ucl.ac.uk/staff/R.Yu/video\_popup/VideoPopup\_pami-compressed.pdf](http://www0.cs.ucl.ac.uk/staff/R.Yu/video_popup/VideoPopup_pami-compressed.pdf)  
9. About \- OpenCV, 访问时间为 五月 19, 2025， [https://opencv.org/about/](https://opencv.org/about/)  
10. Open3D – A Modern Library for 3D Data Processing, 访问时间为 五月 19, 2025， [https://www.open3d.org/](https://www.open3d.org/)  
11. Enhancing UAV–SfM 3D Model Accuracy in High-Relief ... \- MDPI, 访问时间为 五月 19, 2025， [https://www.mdpi.com/2072-4292/11/3/239](https://www.mdpi.com/2072-4292/11/3/239)  
12. (PDF) Robust Fusion of Multi-Source Images for Accurate 3D ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/375541190\_Robust\_Fusion\_of\_Multi-Source\_Images\_for\_Accurate\_3D\_Reconstruction\_of\_Complex\_Urban\_Scenes](https://www.researchgate.net/publication/375541190_Robust_Fusion_of_Multi-Source_Images_for_Accurate_3D_Reconstruction_of_Complex_Urban_Scenes)  
13. xiarain/VINS-Mono \- Gitee, 访问时间为 五月 19, 2025， [https://gitee.com/xiaruiLUT/VINS-Mono](https://gitee.com/xiaruiLUT/VINS-Mono)  
14. VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator \- ar5iv \- arXiv, 访问时间为 五月 19, 2025， [https://ar5iv.labs.arxiv.org/html/1708.03852](https://ar5iv.labs.arxiv.org/html/1708.03852)  
15. (PDF) Efficient structure from motion for large-scale UAV images: A ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/343290671\_Efficient\_structure\_from\_motion\_for\_large-scale\_UAV\_images\_A\_review\_and\_a\_comparison\_of\_SfM\_tools](https://www.researchgate.net/publication/343290671_Efficient_structure_from_motion_for_large-scale_UAV_images_A_review_and_a_comparison_of_SfM_tools)  
16. Gaussian Splatting SLAM — 3D reconstruction using a single ..., 访问时间为 五月 19, 2025， [https://www.reddit.com/r/augmentedreality/comments/1b9yc8l/gaussian\_splatting\_slam\_3d\_reconstruction\_using\_a/](https://www.reddit.com/r/augmentedreality/comments/1b9yc8l/gaussian_splatting_slam_3d_reconstruction_using_a/)  
17. SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2412.09401v1](https://arxiv.org/html/2412.09401v1)  
18. GigaSLAM: Large-Scale Monocular SLAM with Hierachical Gaussian Splats \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2503.08071v1](https://arxiv.org/html/2503.08071v1)  
19. arxiv.org, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2412.12392v1](https://arxiv.org/html/2412.12392v1)  
20. ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual–Inertial, and Multimap SLAM | Request PDF \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/351862633\_ORB-SLAM3\_An\_Accurate\_Open-Source\_Library\_for\_Visual\_Visual-Inertial\_and\_Multimap\_SLAM](https://www.researchgate.net/publication/351862633_ORB-SLAM3_An_Accurate_Open-Source_Library_for_Visual_Visual-Inertial_and_Multimap_SLAM)  
21. 3D reconstruction \- Wikipedia, 访问时间为 五月 19, 2025， [https://en.wikipedia.org/wiki/3D\_reconstruction](https://en.wikipedia.org/wiki/3D_reconstruction)  
22. MonSter: Marry Monodepth to Stereo Unleashes Power \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2501.08643v1](https://arxiv.org/html/2501.08643v1)  
23. arxiv.org, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2501.11841v2](https://arxiv.org/html/2501.11841v2)  
24. (PDF) UseGeo \- A UAV-based multi-sensor dataset for geospatial ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/381534229\_UseGeo\_-\_A\_UAV-based\_multi-sensor\_dataset\_for\_geospatial\_research](https://www.researchgate.net/publication/381534229_UseGeo_-_A_UAV-based_multi-sensor_dataset_for_geospatial_research)  
25. Self-supervised monocular depth estimation from oblique UAV videos, 访问时间为 五月 19, 2025， [https://dspace.library.uu.nl/bitstream/handle/1874/411416/1\_s2.0\_S0924271621000952\_main.pdf?sequence=1](https://dspace.library.uu.nl/bitstream/handle/1874/411416/1_s2.0_S0924271621000952_main.pdf?sequence=1)  
26. Survey on Monocular Metric Depth Estimation \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2501.11841v1](https://arxiv.org/html/2501.11841v1)  
27. \[2501.11841\] Survey on Monocular Metric Depth Estimation \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/abs/2501.11841](https://arxiv.org/abs/2501.11841)  
28. arxiv.org, 访问时间为 五月 19, 2025， [https://arxiv.org/abs/2308.07231](https://arxiv.org/abs/2308.07231)  
29. Tutorial — COLMAP 3.12.0.dev0 documentation, 访问时间为 五月 19, 2025， [https://colmap.github.io/tutorial.html](https://colmap.github.io/tutorial.html)  
30. What is The Difference Between NADIR Images, Orthophotography ..., 访问时间为 五月 19, 2025， [https://www.autelpilot.com/blogs/drone-technology/nadir-orthophotography-oblique](https://www.autelpilot.com/blogs/drone-technology/nadir-orthophotography-oblique)  
31. oblique aerial photography: Topics by Science.gov, 访问时间为 五月 19, 2025， [https://www.science.gov/topicpages/o/oblique+aerial+photography](https://www.science.gov/topicpages/o/oblique+aerial+photography)  
32. Full article: 3D reconstruction of spherical images: a review of ..., 访问时间为 五月 19, 2025， [https://www.tandfonline.com/doi/full/10.1080/10095020.2024.2313328](https://www.tandfonline.com/doi/full/10.1080/10095020.2024.2313328)  
33. www.wcse.org, 访问时间为 五月 19, 2025， [https://www.wcse.org/WCSE\_2024/004.pdf](https://www.wcse.org/WCSE_2024/004.pdf)  
34. Evaluation of the effectiveness of carbon sink restoration in ..., 访问时间为 五月 19, 2025， [https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13279/3044501/Evaluation-of-the-effectiveness-of-carbon-sink-restoration-in-ecological/10.1117/12.3044501.full](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13279/3044501/Evaluation-of-the-effectiveness-of-carbon-sink-restoration-in-ecological/10.1117/12.3044501.full)  
35. isprs-archives.copernicus.org, 访问时间为 五月 19, 2025， [https://isprs-archives.copernicus.org/articles/XLVIII-M-5-2024/183/2025/isprs-archives-XLVIII-M-5-2024-183-2025.pdf](https://isprs-archives.copernicus.org/articles/XLVIII-M-5-2024/183/2025/isprs-archives-XLVIII-M-5-2024-183-2025.pdf)  
36. UAV-Based Oblique Photogrammetry for Outdoor Data Acquisition ..., 访问时间为 五月 19, 2025， [https://www.mdpi.com/2072-4292/9/3/278](https://www.mdpi.com/2072-4292/9/3/278)  
37. COLMAP \- Structure-from-Motion and Multi-View Stereo \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/colmap/colmap](https://github.com/colmap/colmap)  
38. ULSR-GS: Urban Large-scale Surface Reconstruction Gaussian Splatting with Multi-View Geometric Consistency \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2412.01402v2](https://arxiv.org/html/2412.01402v2)  
39. AliceVision | Photogrammetric Computer Vision Framework, 访问时间为 五月 19, 2025， [https://alicevision.org/](https://alicevision.org/)  
40. RTK-georeferenced textured mesh with Meshroom (Drone imagery ..., 访问时间为 五月 19, 2025， [https://github.com/alicevision/Meshroom/issues/2333](https://github.com/alicevision/Meshroom/issues/2333)  
41. (PDF) Comparison between AliceVision Meshroom and ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/366581674\_Comparison\_between\_AliceVision\_Meshroom\_and\_Pix4Dmapper\_Software\_in\_Generating\_Three-Dimensional\_3D\_Photogrammetry\_Software](https://www.researchgate.net/publication/366581674_Comparison_between_AliceVision_Meshroom_and_Pix4Dmapper_Software_in_Generating_Three-Dimensional_3D_Photogrammetry_Software)  
42. Oblique View Selection for Efficient and Accurate Building ... \- MDPI, 访问时间为 五月 19, 2025， [https://www.mdpi.com/2504-446X/6/7/175](https://www.mdpi.com/2504-446X/6/7/175)  
43. simonfuhrmann/mve: Multi-View Environment \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/simonfuhrmann/mve](https://github.com/simonfuhrmann/mve)  
44. MVE – An Image-Based Reconstruction Environment \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/282412561\_MVE\_-\_An\_Image-Based\_Reconstruction\_Environment](https://www.researchgate.net/publication/282412561_MVE_-_An_Image-Based_Reconstruction_Environment)  
45. Typical untextured building models and the multiview texture images ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/figure/Typical-untextured-building-models-and-the-multiview-texture-images-a-c-are-three\_fig7\_357304351](https://www.researchgate.net/figure/Typical-untextured-building-models-and-the-multiview-texture-images-a-c-are-three_fig7_357304351)  
46. gpcv-liujin/Deep3D\_Aerial: This repository provides the ... \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/gpcv-liujin/Deep3D\_Aerial](https://github.com/gpcv-liujin/Deep3D_Aerial)  
47. FaSS-MVS: Fast Multi-View Stereo with Surface-Aware Semi-Global ..., 访问时间为 五月 19, 2025， [https://pmc.ncbi.nlm.nih.gov/articles/PMC11479275/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11479275/)  
48. UAV-GeoLAB/Agisoft-Oblique-Toolkit: This toolkit was ... \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/UAV-GeoLAB/Agisoft-Oblique-Toolkit](https://github.com/UAV-GeoLAB/Agisoft-Oblique-Toolkit)  
49. Application of UAV oblique photography and LiDAR in power facility ..., 访问时间为 五月 19, 2025， [https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13551/3059714/Application-of-UAV-oblique-photography-and-LiDAR-in-power-facility/10.1117/12.3059714.full](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13551/3059714/Application-of-UAV-oblique-photography-and-LiDAR-in-power-facility/10.1117/12.3059714.full)  
50. A Model-Driven Method for Pylon Reconstruction from Oblique UAV ..., 访问时间为 五月 19, 2025， [https://pmc.ncbi.nlm.nih.gov/articles/PMC7038677/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7038677/)  
51. UAV Platforms and the SfM-MVS Approach in the 3D Surveys and ..., 访问时间为 五月 19, 2025， [https://www.mdpi.com/2076-3417/12/24/12886](https://www.mdpi.com/2076-3417/12/24/12886)  
52. Self-supervised monocular depth estimation from oblique UAV videos \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/350856950\_Self-supervised\_monocular\_depth\_estimation\_from\_oblique\_UAV\_videos](https://www.researchgate.net/publication/350856950_Self-supervised_monocular_depth_estimation_from_oblique_UAV_videos)  
53. Autonomous 3D Reconstruction With Small Unmanned Aerial ..., 访问时间为 五月 19, 2025， [https://arc.aiaa.org/doi/10.2514/6.2025-1345](https://arc.aiaa.org/doi/10.2514/6.2025-1345)  
54. \[2504.02084\] Evaluation of Flight Parameters in UAV-based 3D Reconstruction for Rooftop Infrastructure Assessment \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/abs/2504.02084](https://arxiv.org/abs/2504.02084)  
55. Surveying with a drone—explore the benefits and how to start ..., 访问时间为 五月 19, 2025， [https://wingtra.com/surveying-gis/](https://wingtra.com/surveying-gis/)  
56. Use of SfM-MVS approach to nadir and oblique images generated throught aerial cameras to build 2.5D map and 3D models in urban areas \- IRIS Re.Public@polimi.it, 访问时间为 五月 19, 2025， [https://re.public.polimi.it/retrieve/c262a7e8-48dc-4248-a3b2-77cdad4191b2/11311-1157830\_Fregonese.pdf](https://re.public.polimi.it/retrieve/c262a7e8-48dc-4248-a3b2-77cdad4191b2/11311-1157830_Fregonese.pdf)  
57. OpenDroneMap \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/OpenDroneMap](https://github.com/OpenDroneMap)  
58. Documentation \- OpenDroneMap™, 访问时间为 五月 19, 2025， [https://www.opendronemap.org/docs/](https://www.opendronemap.org/docs/)  
59. OpenDroneMap/WebODM: User-friendly, commercial ... \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/OpenDroneMap/WebODM](https://github.com/OpenDroneMap/WebODM)  
60. WebODM Drone Software \- OpenDroneMap™, 访问时间为 五月 19, 2025， [https://www.opendronemap.org/webodm/](https://www.opendronemap.org/webodm/)  
61. Enhanced 3D Urban Scene Reconstruction and Point Cloud Densification using Gaussian Splatting and Google Earth Imagery \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2405.11021](https://arxiv.org/html/2405.11021)  
62. Scene information guided aerial photogrammetric mission recomposition towards detailed level building reconstruction | Request PDF \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/385886098\_Scene\_information\_guided\_aerial\_photogrammetric\_mission\_recomposition\_towards\_detailed\_level\_building\_reconstruction](https://www.researchgate.net/publication/385886098_Scene_information_guided_aerial_photogrammetric_mission_recomposition_towards_detailed_level_building_reconstruction)  
63. arxiv.org, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2409.15914v1](https://arxiv.org/html/2409.15914v1)  
64. \[Revue de papier\] Exploring the potential of collaborative UAV 3D mapping in Kenyan savanna for wildlife research \- Moonlight, 访问时间为 五月 19, 2025， [https://www.themoonlight.io/fr/review/exploring-the-potential-of-collaborative-uav-3d-mapping-in-kenyan-savanna-for-wildlife-research](https://www.themoonlight.io/fr/review/exploring-the-potential-of-collaborative-uav-3d-mapping-in-kenyan-savanna-for-wildlife-research)  
65. Exploring the potential of collaborative UAV 3D mapping in Kenyan savanna for wildlife research \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/384295417\_Exploring\_the\_potential\_of\_collaborative\_UAV\_3D\_mapping\_in\_Kenyan\_savanna\_for\_wildlife\_research](https://www.researchgate.net/publication/384295417_Exploring_the_potential_of_collaborative_UAV_3D_mapping_in_Kenyan_savanna_for_wildlife_research)  
66. json87/ParallelSfM: Efficient Structure from Motion for Large ... \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/json87/ParallelSfM](https://github.com/json87/ParallelSfM)  
67. Imaging geometry for UAV-based oblique photogrammetry: (a ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/figure/Imaging-geometry-for-UAV-based-oblique-photogrammetry-a-imaging-geometry-for-roll\_fig2\_315318564](https://www.researchgate.net/figure/Imaging-geometry-for-UAV-based-oblique-photogrammetry-a-imaging-geometry-for-roll_fig2_315318564)  
68. Digital Terrain Models Generated with Low-Cost UAV Photogrammetry: Methodology and Accuracy \- MDPI, 访问时间为 五月 19, 2025， [https://www.mdpi.com/2220-9964/10/5/285](https://www.mdpi.com/2220-9964/10/5/285)  
69. Traditional Surveying vs. UAV Drone-Based Structure-from-Motion Advancements in Topographical Mapping Accuracy and Efficiency \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/388177304\_Traditional\_Surveying\_vs\_UAV\_Drone-Based\_Structure-from-Motion\_Advancements\_in\_Topographical\_Mapping\_Accuracy\_and\_Efficiency](https://www.researchgate.net/publication/388177304_Traditional_Surveying_vs_UAV_Drone-Based_Structure-from-Motion_Advancements_in_Topographical_Mapping_Accuracy_and_Efficiency)  
70. (PDF) Three-dimensional Visualization of Overhead Transmission ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/376427053\_Three-dimensional\_Visualization\_of\_Overhead\_Transmission\_Lines\_with\_UAV-LiDAR\_Point\_Cloud\_Data](https://www.researchgate.net/publication/376427053_Three-dimensional_Visualization_of_Overhead_Transmission_Lines_with_UAV-LiDAR_Point_Cloud_Data)  
71. Improvement of 3D Power Line Extraction from Multiple Low-Cost UAV Imagery Using Wavelet Analysis \- MDPI, 访问时间为 五月 19, 2025， [https://www.mdpi.com/1424-8220/19/3/700](https://www.mdpi.com/1424-8220/19/3/700)  
72. Improvement of 3D Power Line Extraction from Multiple Low-Cost UAV Imagery Using Wavelet Analysis \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/331011574\_Improvement\_of\_3D\_Power\_Line\_Extraction\_from\_Multiple\_Low-Cost\_UAV\_Imagery\_Using\_Wavelet\_Analysis](https://www.researchgate.net/publication/331011574_Improvement_of_3D_Power_Line_Extraction_from_Multiple_Low-Cost_UAV_Imagery_Using_Wavelet_Analysis)  
73. SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/html/2412.09401v3](https://arxiv.org/html/2412.09401v3)  
74. MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors \- OpenCV, 访问时间为 五月 19, 2025， [https://opencv.org/blog/mast3r-slam/](https://opencv.org/blog/mast3r-slam/)  
75. \[2412.12392\] MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/abs/2412.12392](https://arxiv.org/abs/2412.12392)  
76. UZ-SLAMLab/ORB\_SLAM3: ORB-SLAM3: An Accurate ... \- GitHub, 访问时间为 五月 19, 2025， [https://github.com/UZ-SLAMLab/ORB\_SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3)  
77. \[2503.08071\] GigaSLAM: Large-Scale Monocular SLAM with Hierachical Gaussian Splats \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/abs/2503.08071](https://arxiv.org/abs/2503.08071)  
78. arxiv.org, 访问时间为 五月 19, 2025， [https://arxiv.org/pdf/2501.11841](https://arxiv.org/pdf/2501.11841)  
79. \[2501.08643\] MonSter: Marry Monodepth to Stereo Unleashes Power \- arXiv, 访问时间为 五月 19, 2025， [https://arxiv.org/abs/2501.08643](https://arxiv.org/abs/2501.08643)  
80. Open source SfM? : r/photogrammetry \- Reddit, 访问时间为 五月 19, 2025， [https://www.reddit.com/r/photogrammetry/comments/1i0nvex/open\_source\_sfm/](https://www.reddit.com/r/photogrammetry/comments/1i0nvex/open_source_sfm/)  
81. ULSR-GS: Urban Large-scale Surface Reconstruction Gaussian Splatting with Multi-View Geometric Consistency \- ResearchGate, 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/391234157\_ULSR-GS\_Urban\_Large-scale\_Surface\_Reconstruction\_Gaussian\_Splatting\_with\_Multi-View\_Geometric\_Consistency](https://www.researchgate.net/publication/391234157_ULSR-GS_Urban_Large-scale_Surface_Reconstruction_Gaussian_Splatting_with_Multi-View_Geometric_Consistency)  
82. Multi-tiling neural radiance field (NeRF)—geometric assessment on ..., 访问时间为 五月 19, 2025， [https://www.researchgate.net/publication/380571889\_Multi-tiling\_neural\_radiance\_field\_NeRF-geometric\_assessment\_on\_large-scale\_aerial\_datasets](https://www.researchgate.net/publication/380571889_Multi-tiling_neural_radiance_field_NeRF-geometric_assessment_on_large-scale_aerial_datasets)